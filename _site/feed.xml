<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-11-21T17:47:33+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Luis Pereira</title><subtitle>Notes Regarding DB&apos;s Etc</subtitle><entry><title type="html">Delta Lake Atomicity</title><link href="http://localhost:4000/delta-lake/2025/11/21/delta-table-atomicity.html" rel="alternate" type="text/html" title="Delta Lake Atomicity" /><published>2025-11-21T00:00:00+00:00</published><updated>2025-11-21T00:00:00+00:00</updated><id>http://localhost:4000/delta-lake/2025/11/21/delta-table-atomicity</id><content type="html" xml:base="http://localhost:4000/delta-lake/2025/11/21/delta-table-atomicity.html"><![CDATA[<p>I wanted to clarify to myself how we achieve Atomicity in Delta Lake and it‚Äôs easier for me to compare it to traditional databases.</p>

<p>Atomicity means that when we commit a transaction it‚Äôs an all-or-nothing operation. Either the transaction succeeds or it fails, nothing in between. Consistency means that despite our transaction being atomic, if some database constraint (e.g., a foreign key) is violated, then the operation is rejected and rolled back in spite of the commits being atomic. This distinction is important and will become clear why later. Atomicity pertains to the mechanism, whereas consistency checks if the transactions make logical sense given the constraints of the data model.</p>

<p>Let‚Äôs first cover how ‚Äútraditional‚Äù databases like MySQL and Postgres achieve atomicity with the WAL. It‚Äôs best understood from the perspective of <strong>recovery</strong>:</p>

<p>We make changes to pages in memory - they can be flushed to disk at unpredictable times. Imagine: we modify a page, the buffer pool keeps it in memory (maybe it‚Äôs pinned), and the DB crashes before it‚Äôs written to disk. That means our commit was not durable - the user received a success message but the page was still in RAM.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Traditional DB - Without WAL]

Transaction modifies Page X in buffer pool
  ‚Üì
User gets "COMMIT SUCCESS"
  ‚Üì
üí• CRASH (before page flushes)
  ‚Üì
Page X changes lost forever
</code></pre></div></div>

<p>By writing the WAL (with <code class="language-plaintext highlighter-rouge">fsync</code>) to disk first before acknowledging the COMMIT, the buffer pool can flush pages whenever it wants (following something like LRU-K). If the DB crashes, we simply replay the log, ensuring no partial writes.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Traditional DB - With WAL]

1. Modify Page X in memory
2. Write changes to WAL + fsync  ‚úì
3. Return "COMMIT SUCCESS" to user
4. (Later) Flush Page X to disk
   
If crash happens at step 4:
‚Üí Replay WAL on restart
‚Üí Page X changes restored
</code></pre></div></div>

<p>So how does the transaction log in the Delta format give us atomicity? After all, it‚Äôs not a WAL, is it?</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Delta Lake Architecture]

Compute Engine (Spark/DuckDB/Trino)
  ‚Üì
Delta Libraries (embedded)
  ‚Üì
Object Storage (S3/GCS/ADLS)
</code></pre></div></div>

<p>In the Delta format, we have a compute engine (e.g., Spark, DuckDB, Trino). The engine manages data in memory, reading and writing Parquet files. The Delta libraries are embedded in the engine to intercept and interact with the storage layer (our proverbial disk) - in this case, distributed object storage (S3, GCS, ADLS, etc.).</p>

<p><strong>Here‚Äôs the key difference: There is no recovery‚Ä¶ what?</strong></p>

<p>The compute engine does not update pages in place, so there‚Äôs no need to worry about unpredictable page flushing to disk. The Parquet files are rewritten to storage, and a JSON log entry is added describing the write operation (copy-on-write). The JSON log entry says:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Remove: file_A.parquet</code> ‚Üê The one we modified</li>
  <li><code class="language-plaintext highlighter-rouge">Add: file_B.parquet</code> ‚Üê The new one with modified data</li>
</ul>

<p>Therefore, if there‚Äôs a crash (typically some network error), either the JSON entry exists or it doesn‚Äôt. Even if the new Parquet files exist, they are logically invisible (orphaned) to the compute engine. Thus, the sequence is opposite to traditional databases: we write the Parquet files first, and only then write our JSON log.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Delta Lake Commit Sequence]

1. Write file_B.parquet (new data) ‚úì
2. Write JSON log entry atomically  ‚úì
   {
     "remove": {"path": "file_A.parquet"},
     "add": {"path": "file_B.parquet"}
   }
3. Return "COMMIT SUCCESS"

If crash at step 1:
‚Üí file_B.parquet orphaned
‚Üí No log entry ‚Üí logically invisible
‚Üí No recovery needed

Object storage guarantees:
Single file write is atomic ‚úì
</code></pre></div></div>

<p>This opens a new question! How do we handle this seemingly explosive storage growth? That‚Äôll be the next note.</p>]]></content><author><name></name></author><category term="Delta-Lake" /><summary type="html"><![CDATA[I wanted to clarify to myself how we achieve Atomicity in Delta Lake and it‚Äôs easier for me to compare it to traditional databases.]]></summary></entry></feed>